// components/auth/face-scanner/video-scanner.tsx
"use client";

import { useCallback, useRef, useState, useEffect } from "react";
import { Button } from "@/components/ui/button";
import { useToast } from "@/hooks/use-toast";
import { useFaceAPIGitHub } from "./hooks/use-face-api-github";

export interface FaceDetectionData {
  detection: any;
  landmarks?: any; // ‚úÖ –î–æ–±–∞–≤–ª—è–µ–º landmarks
  descriptor?: Float32Array; // ‚úÖ –î–æ–±–∞–≤–ª—è–µ–º –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä
  box: {
    x: number;
    y: number;
    width: number;
    height: number;
  };
}

interface VideoScannerProps {
  onFaceDetected: (faceData: FaceDetectionData) => void;
  disabled?: boolean;
  className?: string;
}

export function VideoScanner({ onFaceDetected, disabled = false, className }: VideoScannerProps) {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const detectionIntervalRef = useRef<NodeJS.Timeout | null>(null);
  
  const [isScanning, setIsScanning] = useState(false);
  const [detectionStatus, setDetectionStatus] = useState<string>("");
  const [faceCount, setFaceCount] = useState(0);
  const [modelsStatus, setModelsStatus] = useState<string>("");
  
  const { toast } = useToast();
  const { faceapi, modelsLoaded, isLoadingModels, modelSource, error, loadFaceAPI } = useFaceAPIGitHub();

  // ‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –º–æ–¥–µ–ª–µ–π
  const loadAllModels = useCallback(async () => {
    if (!faceapi) return;
    
    try {
      setModelsStatus("ü§ñ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π...");
      
      const githubUrl = 'https://raw.githubusercontent.com/justadudewhohacks/face-api.js/a86f011d72124e5fb93e59d5c4ab98f699dd5c9c/weights';
      
      // –ó–∞–≥—Ä—É–∂–∞–µ–º landmarks –º–æ–¥–µ–ª—å
      if (!faceapi.nets.faceLandmark68Net.isLoaded) {
        console.log('üì• –ó–∞–≥—Ä—É–∂–∞–µ–º face landmarks...');
        await faceapi.nets.faceLandmark68Net.loadFromUri(githubUrl);
        console.log('‚úÖ Face landmarks –∑–∞–≥—Ä—É–∂–µ–Ω—ã');
      }
      
      // –ó–∞–≥—Ä—É–∂–∞–µ–º recognition –º–æ–¥–µ–ª—å
      if (!faceapi.nets.faceRecognitionNet.isLoaded) {
        console.log('üì• –ó–∞–≥—Ä—É–∂–∞–µ–º face recognition...');
        await faceapi.nets.faceRecognitionNet.loadFromUri(githubUrl);
        console.log('‚úÖ Face recognition –∑–∞–≥—Ä—É–∂–µ–Ω—ã');
      }
      
      setModelsStatus("‚úÖ –í—Å–µ –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã");
      
    } catch (error) {
      console.error('‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π:', error);
      setModelsStatus("‚ö†Ô∏è –ë–∞–∑–æ–≤–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è –¥–æ—Å—Ç—É–ø–Ω–∞");
    }
  }, [faceapi]);

  // ‚úÖ –ü–æ–ª–Ω–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è —Å landmarks –∏ –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–∞–º–∏
  const detectFace = useCallback(async () => {
    if (!videoRef.current || !canvasRef.current || !faceapi || !modelsLoaded) {
      return;
    }

    const video = videoRef.current;
    const canvas = canvasRef.current;

    try {
      const displaySize = { width: video.videoWidth, height: video.videoHeight };
      faceapi.matchDimensions(canvas, displaySize);

      // ‚úÖ –ü–æ–ª–Ω–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è: detection + landmarks + descriptor
      const detections = await faceapi
        .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions({
          inputSize: 416,
          scoreThreshold: 0.5
        }))
        .withFaceLandmarks()
        .withFaceDescriptors();

      const ctx = canvas.getContext('2d');
      if (ctx) {
        ctx.clearRect(0, 0, canvas.width, canvas.height);
      }

      const resizedDetections = faceapi.resizeResults(detections, displaySize);
      
      // ‚úÖ –†–∏—Å—É–µ–º –¥–µ—Ç–µ–∫—Ü–∏—é –∏ landmarks
      faceapi.draw.drawDetections(canvas, resizedDetections);
      faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);

      setFaceCount(detections.length);

      if (detections.length === 1) {
        const detection = detections[0];
        const faceData: FaceDetectionData = {
          detection: detection.detection,
          landmarks: detection.landmarks,
          descriptor: detection.descriptor,
          box: {
            x: detection.detection.box.x,
            y: detection.detection.box.y,
            width: detection.detection.box.width,
            height: detection.detection.box.height,
          }
        };

        setDetectionStatus("‚úÖ –õ–∏—Ü–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–æ");
        onFaceDetected(faceData);
      } else if (detections.length === 0) {
        setDetectionStatus("üë§ –ü–æ–º–µ—Å—Ç–∏—Ç–µ –ª–∏—Ü–æ –≤ –∫–∞–¥—Ä");
      } else {
        setDetectionStatus("‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ª–∏—Ü");
      }

    } catch (error) {
      console.error('‚ùå –û—à–∏–±–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏:', error);
      setDetectionStatus("‚ùå –û—à–∏–±–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏");
    }
  }, [faceapi, modelsLoaded, onFaceDetected]);

  const startScanning = useCallback(async () => {
    if (disabled) {
      toast({
        variant: "destructive",
        title: "–°–∫–∞–Ω–µ—Ä –æ—Ç–∫–ª—é—á–µ–Ω",
        description: "–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ª–∏—Ü–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ",
      });
      return;
    }

    setIsScanning(true);
    setDetectionStatus("üöÄ –ó–∞–ø—É—Å–∫...");

    try {
      console.log('üé• –ó–∞–ø—É—Å–∫–∞–µ–º –∫–∞–º–µ—Ä—É...');
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { 
          width: { ideal: 640 },
          height: { ideal: 480 }, 
          facingMode: "user"
        }
      });
      
      streamRef.current = stream;
      
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        
        await new Promise<void>((resolve) => {
          if (videoRef.current) {
            videoRef.current.onloadedmetadata = () => resolve();
          }
        });

        if (!faceapi || !modelsLoaded) {
          setDetectionStatus("ü§ñ –ó–∞–≥—Ä—É–∑–∫–∞ Face API –∏–∑ GitHub...");
          await loadFaceAPI();
        }
        
        // ‚úÖ –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏
        await loadAllModels();
        
        setDetectionStatus("üîç –ü–æ–∏—Å–∫ –ª–∏—Ü–∞...");
        detectionIntervalRef.current = setInterval(detectFace, 300);
      }

    } catch (error) {
      console.error("‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞:", error);
      setIsScanning(false);
      setDetectionStatus("‚ùå –û—à–∏–±–∫–∞");
      
      toast({
        variant: "destructive",
        title: "–û—à–∏–±–∫–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è",
        description: (error as Error).message,
      });
    }
  }, [disabled, faceapi, modelsLoaded, loadFaceAPI, loadAllModels, detectFace, toast]);

  const stopScanning = useCallback(() => {
    setIsScanning(false);
    setDetectionStatus("");
    setModelsStatus("");
    setFaceCount(0);
    
    if (detectionIntervalRef.current) {
      clearInterval(detectionIntervalRef.current);
      detectionIntervalRef.current = null;
    }
    
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
    
    if (videoRef.current) {
      videoRef.current.srcObject = null;
    }

    if (canvasRef.current) {
      const ctx = canvasRef.current.getContext('2d');
      if (ctx) {
        ctx.clearRect(0, 0, canvasRef.current.width, canvasRef.current.height);
      }
    }
  }, []);

  useEffect(() => {
    return () => stopScanning();
  }, [stopScanning]);

  return (
    <div className={`space-y-4 ${className}`}>
      {/* –°—Ç–∞—Ç—É—Å –∑–∞–≥—Ä—É–∑–∫–∏ */}
      {isLoadingModels && (
        <div className="p-3 bg-yellow-100 border border-yellow-400 text-yellow-700 rounded-lg">
          <div className="flex items-center space-x-2">
            <div className="animate-spin rounded-full h-4 w-4 border-b-2 border-yellow-600"></div>
            <span>–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –∏–∑ GitHub Raw...</span>
          </div>
        </div>
      )}

      {/* –°—Ç–∞—Ç—É—Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π */}
      {modelsStatus && (
        <div className="p-2 bg-blue-100 text-blue-800 rounded text-sm">
          {modelsStatus}
        </div>
      )}

      {/* –ò—Å—Ç–æ—á–Ω–∏–∫ –º–æ–¥–µ–ª–µ–π */}
      {modelSource && (
        <div className="p-2 bg-green-100 text-green-800 rounded text-sm">
          ‚úÖ –ú–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑: {modelSource}
        </div>
      )}

      {/* –û—à–∏–±–∫–∏ */}
      {error && (
        <div className="p-3 bg-red-100 border border-red-400 text-red-700 rounded-lg">
          ‚ùå –û—à–∏–±–∫–∞: {error}
        </div>
      )}

      {/* –°—Ç–∞—Ç—É—Å –¥–µ—Ç–µ–∫—Ü–∏–∏ */}
      {detectionStatus && (
        <div className="p-3 bg-blue-100 border border-blue-400 text-blue-700 rounded-lg text-center">
          <div className="font-medium">{detectionStatus}</div>
          {faceCount > 0 && (
            <div className="text-sm mt-1">–õ–∏—Ü –≤ –∫–∞–¥—Ä–µ: {faceCount}</div>
          )}
        </div>
      )}

      {/* –ö–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è */}
      <div className="flex space-x-2">
        {!isScanning ? (
          <Button 
            onClick={startScanning} 
            disabled={disabled || isLoadingModels}
            className="flex-1"
          >
            {isLoadingModels ? "–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ GitHub..." : "üé• –ù–∞—á–∞—Ç—å —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ"}
          </Button>
        ) : (
          <Button 
            onClick={stopScanning} 
            variant="destructive"
            className="flex-1"
          >
            ‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
          </Button>
        )}
      </div>

      {/* –í–∏–¥–µ–æ */}
      <div className="relative">
        <video
          ref={videoRef}
          autoPlay
          playsInline
          muted
          className="w-full rounded-lg border"
        />
        <canvas
          ref={canvasRef}
          className="absolute top-0 left-0 w-full h-full rounded-lg"
        />
      </div>
    </div>
  );
}
